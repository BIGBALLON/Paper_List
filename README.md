# My Paper Reading List

## Convolutional Neural Network

- (**LeNet**) LeCun, Yann, et al. "**Gradient-based learning applied to document recognition**." Proceedings of the IEEE 86.11 (**1998**).
- (**AlexNet**) Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "**Imagenet classification with deep convolutional neural networks**." Advances in neural information processing systems. (**2012**).
- (**ZFNet**) Zeiler, Matthew D., and Rob Fergus. "**Visualizing and understanding convolutional networks**." European conference on computer vision. Springer, Cham, (**2014**).
- (**NIN**) Lin, Min, Qiang Chen, and Shuicheng Yan. "**Network in network**." (**2013**). [[arXiv:1312.4400][1]]
- (**VGGNet**) Simonyan, Karen, and Andrew Zisserman. "**Very deep convolutional networks for large-scale image recognition**."(2014). [[arXiv:1409.1556][2]]
- (**GoogLeNet**) Szegedy, Christian, et al. "**Going deeper with convolutions**." Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.
- (**BN**) Ioffe, Sergey, and Christian Szegedy. "**Batch normalization: Accelerating deep network training by reducing internal covariate shift**." International Conference on Machine Learning. (**2015**). [[arXiv:1502.03167][3]]
- (**ResNet**) He, Kaiming, et al. "**Deep residual learning for image recognition**." Proceedings of the IEEE conference on computer vision and pattern recognition. (**2016**). [[arXiv:1512.03385][4]]  [CVPR 2016 Best Paper] :star:
- (**Pre-active**) He, Kaiming, et al. "**Identity mappings in deep residual networks**." European Conference on Computer Vision. Springer International Publishing. (**2016**). [[arXiv:1603.05027][5]]
- (**Wide ResNet**) Zagoruyko, Sergey, and Nikos Komodakis. "**Wide residual networks**." (**2016**). [[arXiv:1605.07146][6]]
- (**ResNeXt**) Xie, Saining, et al. "**Aggregated residual transformations for deep neural networks**." 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, (**2017**). [[arXiv:1611.05431][7]]
- (**DenseNet**) Huang, Gao, et al. "**Densely connected convolutional networks**." (**2016**). [[arXiv:1608.06993][8]] 
- (**DPN**) Chen, Yunpeng, et al. "**Dual path networks**." Advances in Neural Information Processing Systems. (**2017**). [[arXiv:1707.01629][9]]
- (**SENet**) Hu, Jie, Li Shen, and Gang Sun. "**Squeeze-and-excitation networks**." (**2017**). [[arXiv:1709.01507][10]]
- (**CondenseNet**) Huang, Gao, et al. "CondenseNet: An Efficient DenseNet using Learned Group Convolutions." (**2017**). [[arXiv:1711.09224][11]] 


## (Deep) Reinforcement Learning  

- **Value-based**
    - (**DQN**) Deep Q Network 
        - Mnih, Volodymyr, et al. "**Playing atari with deep reinforcement learning**." (**2013**). [[arXiv:1312.5602][12]] 
        - Mnih, Volodymyr, et al. "**Human-level control through deep reinforcement learning**."(**2015**). [[Nature 518.7540][13]] :star:
    - Other improvements:
        - (**DDQN**) Van Hasselt, Hado, Arthur Guez, and David Silver. "**Deep Reinforcement Learning with Double Q-Learning**." AAAI. **2016**. [[arXiv:1509.06461][14]]
        - Schaul, Tom, et al. "**Prioritized experience replay**."(**2015**). [[arXiv:1511.05952][15]] 
        - Wang, Ziyu, et al. "**Dueling network architectures for deep reinforcement learning**." (**2015**). [[arXiv:1511.06581][16]]  [ICML2016 Best Paper]
- **Actor-Critic**
    - (**DDPG**) Lillicrap, Timothy P., et al. "**Continuous control with deep reinforcement learning**." (**2015**). [[arXiv:1509.02971][17]]
    - (**A3C**) Mnih, Volodymyr, et al. "**Asynchronous methods for deep reinforcement learning**." ICML (**2016**). [[arXiv:1602.01783][18]] :star:
    - (**ACER**) Wang, Ziyu, et al. "**Sample efficient actor-critic with experience replay**." (**2016**). [[arXiv:1611.01224][19]]
    - (**ACKTR**) Wu, Yuhuai, et al. "**Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation**." Advances in Neural Information Processing Systems. (**2017**). [[arXiv:1708.05144][20]]
- **More**
    - (**UNREAL**) Jaderberg, Max, et al. "**Reinforcement learning with unsupervised auxiliary tasks**." (**2016**). [[arXiv:1611.05397][21]] 
    - (**TRPO**) Schulman, John, et al. "**Trust region policy optimization**." Proceedings of the 32nd International Conference on Machine Learning (ICML-15). (**2015**). [[arXiv:1502.05477][22]]
    - (**DPPO**) Schulman, John, et al. "**Proximal policy optimization algorithms**." (**2017**). [[arXiv:1707.06347][23]]
    - Heess, Nicolas, et al. "**Emergence of locomotion behaviours in rich environments**." (**2017**). [[arXiv:1707.02286][24]]
    - Hessel, Matteo, et al. "**Rainbow: Combining Improvements in Deep Reinforcement Learning**." (**2017**). [[arXiv:1710.02298][25]]


## Computer Games 

-  **2048 Like Games**
    - Szubert, Marcin, and Wojciech Jaśkowski. "**Temporal difference learning of n-tuple networks for the game 2048**." Computational Intelligence and Games (CIG), IEEE Conference on. IEEE, (**2014**).
    - Wu, I-Chen, et al. "**Multi-stage temporal difference learning for 2048**." Technologies and Applications of Artificial Intelligence. Springer, Cham, (**2014**).
    - Yeh, Kun-Hao, et al. "**Multi-stage temporal difference learning for 2048-like games**." IEEE Transactions on Computational Intelligence and AI in Games (**2016**).
    - Jaskowski, Wojciech. "**Mastering 2048 with Delayed Temporal Coherence Learning, Multi-Stage Weight Promotion, Redundant Encoding and Carousel Shaping**." IEEE Transactions on Computational Intelligence and AI in Games (**2017**). :star:
- **AlphaGo** 
    -  Silver, David, et al. "**Mastering the game of Go with deep neural networks and tree search**." [Nature 529.7587][26] (**2016**): 484-489. :star:
    -  Silver, David, et al. "**Mastering the game of go without human knowledge**." [Nature 550.7676][27] (**2017**): 354. :star:
    -  Silver, David, et al. "**Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm**."  (**2017**). [[arXiv:1712.01815][28]] :star:
- **More**
    - Lai, Matthew. "**Giraffe: Using deep reinforcement learning to play chess**." (**2015**). [arXiv:1509.01549][29] 
    -  Vinyals, Oriol, et al. "**StarCraft II: a new challenge for reinforcement learning**." (**2017**). [[arXiv:1708.04782][30]]    
    -  Maddison, Chris J., et al. "**Move evaluation in go using deep convolutional neural networks**." (**2014**). [[arXiv:1412.6564][31]]
    -  Soeda, Shunsuke, Tomoyuki Kaneko, and Tetsuro Tanaka. "**Dual lambda search and shogi endgames**." Advances in Computer Games. Springer, Berlin, Heidelberg, (**2005**).
    
## Generative Adversarial Network

- Goodfellow, Ian, et al. "**Generative adversarial nets**." Advances in neural information processing systems. (**2014**). [[arXiv:1406.2661][32]]
- Mirza, Mehdi, and Simon Osindero. "**Conditional generative adversarial nets**." (**2014**). [[arXiv:1411.1784][33]]
- Radford, Alec, Luke Metz, and Soumith Chintala. "Unsupervised representation learning with deep convolutional generative adversarial networks." (**2015**). [[arXiv:1511.06434][34]]
- Reed, Scott, et al. "**Generative adversarial text to image synthesis**." (**2016**). [[arXiv:1605.05396][35]]
- Shrivastava, Ashish, et al. "Learning from simulated and unsupervised images through adversarial training."(**2016**). [[arXiv:1612.07828][36]]
- Arjovsky, Martin, Soumith Chintala, and Léon Bottou. "**Wasserstein gan**." (**2017**). [[arXiv:1701.07875][37]]

## Others 

- Li, Yuxi. "**Deep reinforcement learning: An overview**." (**2017**). [[arXiv:1701.07274][38]]
- [AdversarialNetsPapers][39]
- [deep-reinforcement-learning-papers][40]


  [1]: https://arxiv.org/abs/1312.4400
  [2]: https://arxiv.org/abs/1409.1556
  [3]: https://arxiv.org/abs/1502.03167
  [4]: https://arxiv.org/abs/1512.03385
  [5]: https://arxiv.org/abs/1603.05027
  [6]: https://arxiv.org/abs/1605.07146
  [7]: https://arxiv.org/abs/1611.05431
  [8]: https://arxiv.org/abs/1608.06993
  [9]: https://arxiv.org/abs/1707.01629
  [10]: https://arxiv.org/abs/1709.01507
  [11]: https://arxiv.org/abs/1711.09224
  [12]: https://arxiv.org/abs/1312.5602
  [13]: https://www.nature.com/articles/nature14236
  [14]: https://arxiv.org/abs/1509.06461
  [15]: https://arxiv.org/abs/1511.05952
  [16]: https://arxiv.org/abs/1511.06581
  [17]: https://arxiv.org/abs/1509.02971
  [18]: https://arxiv.org/abs/1602.01783
  [19]: https://arxiv.org/abs/1611.01224
  [20]: https://arxiv.org/abs/1708.05144
  [21]: https://arxiv.org/abs/1611.05397
  [22]: https://arxiv.org/abs/1502.05477
  [23]: https://arxiv.org/abs/1707.06347
  [24]: https://arxiv.org/abs/1707.02286
  [25]: https://arxiv.org/abs/1710.02298
  [26]: https://www.nature.com/articles/nature16961
  [27]: https://www.nature.com/articles/nature24270
  [28]: https://arxiv.org/abs/1712.01815
  [29]: https://arxiv.org/abs/1509.01549
  [30]: https://arxiv.org/abs/1708.04782
  [31]: https://arxiv.org/abs/1412.6564
  [32]: https://arxiv.org/abs/1406.2661
  [33]: https://arxiv.org/abs/1411.1784
  [34]: https://arxiv.org/abs/1511.06434
  [35]: https://arxiv.org/abs/1605.05396
  [36]: https://arxiv.org/abs/1612.07828
  [37]: https://arxiv.org/abs/1701.07875
  [38]: https://arxiv.org/abs/1701.07274
  [39]: https://github.com/zhangqianhui/AdversarialNetsPapers
  [40]: https://github.com/junhyukoh/deep-reinforcement-learning-papers#all-papers